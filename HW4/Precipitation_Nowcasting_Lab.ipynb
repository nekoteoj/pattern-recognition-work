{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Networks with Keras ##\n",
    "\n",
    "In this exercise, you are going to build a set of deep learning models on a real world task using Tensorflow and Keras. Tensorflow is a deep learning framwork developed by Google, and Keras is a frontend library built on top of Tensorflow (or Theano, CNTK) to provide an easier way to use standard layers and networks.\n",
    "\n",
    "To complete this exercise, you will need to build deep learning models for precipitation nowcasting. You will build a subset of the models shown below:\n",
    "- Fully Connected (Feedforward) Neural Network\n",
    "- Two-Dimentional Convolution Neural Network (2D-CNN)\n",
    "- Recurrent Neural Network with Gated Recurrent Unit (GRU)\n",
    "\n",
    "and one more model of your choice to achieve the highest score possible.\n",
    "\n",
    "We provide the code for data cleaning and some starter code for keras in this notebook but feel free to modify those parts to suit your needs. You can also complete this exercise using only Tensorflow (without using Keras). Feel free to use additional libraries (e.g. scikit-learn) as long as you have a model for each type mentioned above.\n",
    "\n",
    "This notebook assumes you have already installed Tensorflow and Keras with python3 and had GPU enabled. If you run this exercise on GCloud using the provided disk image you are all set.\n",
    "\n",
    "As a reminder,\n",
    "\n",
    "### Don't forget to shut down your instance on Gcloud when you are not using it ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation Nowcasting ##\n",
    "\n",
    "Precipitation nowcasting is the the task of predicting the amount of rainfall in a certain region given some kind of sensor data.  The term nowcasting refers to tasks that try to predict the current or near future conditions (within 6 hours). \n",
    "\n",
    "You will be given satellite images in 3 different bands covering a 5 by 5 region from different parts of Thailand. In other words, your input will be a 5x5x3 image. Your task is to predict the amount of rainfal in the center pixel. You will first do the prediction using just a simple fully-connected neural network that view each pixel as different input features.\n",
    "\n",
    "Since the your input is basically an image, we will then view the input as an image and apply CNN to do the prediction. Finally, we can also add a time component since weather prediction can benefit greatly using previous time frames. Each data point actually contain 5 time steps, so each input data point has a size of 5x5x5x3 (time x height x width x channel), and the output data has a size of 5 (time). You will use this time information when you work with RNNs.\n",
    "\n",
    "Finally, we would like to thank the Thai Meteorological Department for providing the data for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explanation #\n",
    "\n",
    "The data is an hourly measurement of water vapor in the atmosphere, and two infrared measurements of cloud imagery on a latitude-longitude coordinate. Each measurement is illustrated below as an image. These three features are included as different channels in your input data.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/burin-n/pattern-recognition/master/HW4/images/wvapor.png\" width=\"200\"> <img src=\"https://raw.githubusercontent.com/burin-n/pattern-recognition/master/HW4/images/cloud1.png\" width=\"200\"> <img src=\"https://raw.githubusercontent.com/burin-n/pattern-recognition/master/HW4/images/cloud2.png\" width=\"200\">\n",
    "\n",
    "We also provide the hourly precipitation (rainfall) records in the month of June, July, August, September, and October from weather stations spreaded around the country. A 5x5 grid around each weather station at a particular time will be paired with the precipitation recorded at the corresponding station as input and output data. Finally, five adjacent timesteps are stacked into one sequence.\n",
    "\n",
    "The month of June-August are provided as training data, while the months of September and October are used as validation and test sets, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(months, data_dir='dataset'):\n",
    "    features = np.array([], dtype=np.float32).reshape(0,5,5,5,3)\n",
    "    labels = np.array([], dtype=np.float32).reshape(0,5)\n",
    "    for m in months:\n",
    "        filename = 'features-m{}.pk'.format(m)\n",
    "        with open(os.path.join(data_dir,filename), 'rb') as file:\n",
    "            features_temp = pickle.load(file)\n",
    "        features = np.concatenate((features, features_temp), axis=0)\n",
    "        \n",
    "        filename = 'labels-m{}.pk'.format(m)\n",
    "        with open(os.path.join(data_dir,filename), 'rb') as file:\n",
    "            labels_temp = pickle.load(file)\n",
    "        labels = np.concatenate((labels, labels_temp), axis=0)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data from month 6,7,8 as training set\n",
    "x_train, y_train = read_data(months=[6,7,8])\n",
    "\n",
    "# use data from month 9 as validation set\n",
    "x_val, y_val = read_data(months=[9])\n",
    "\n",
    "# use data from month 10 as test set\n",
    "x_test, y_test = read_data(months=[10])\n",
    "\n",
    "print('x_train shape:',x_train.shape)\n",
    "print('y_train shape:', y_train.shape, '\\n')\n",
    "print('x_val shape:',x_val.shape)\n",
    "print('y_val shape:', y_val.shape, '\\n')\n",
    "print('x_test shape:',x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**features** \n",
    "- dim 0: number of entries\n",
    "- dim 1: number of time-steps in ascending order\n",
    "- dim 2,3: a 5x5 grid around rain-measued station\n",
    "- dim 4: water vapor and two cloud imagenaries \n",
    "\n",
    "**labels**\n",
    "- dim 0: number of entries\n",
    "- dim 1: number of precipitation for each time-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mean = np.mean(X)\n",
    "    var = np.var(X)\n",
    "    return (X - mean) / var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train)\n",
    "x_val = normalize(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three-Layer Feedforward Neural Networks\n",
    "\n",
    "Below, the code for creating a 3-layers fully connected neural network in keras is provided. Run the code and make sure you understand what you are doing. Then, report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset need to be reshaped to make it suitable for feedforword model\n",
    "def preprocess_for_ff(x_train, y_train, x_val, y_val):\n",
    "    x_train_ff = x_train.reshape((-1, 5*5*3))\n",
    "    y_train_ff = y_train.reshape((-1, 1))\n",
    "    x_val_ff = x_val.reshape((-1, 5*5*3))\n",
    "    y_val_ff = y_val.reshape((-1, 1))\n",
    "    return x_train_ff, y_train_ff, x_val_ff, y_val_ff\n",
    "\n",
    "x_train_ff, y_train_ff, x_val_ff, y_val_ff = preprocess_for_ff(x_train, y_train, x_val, y_val)\n",
    "print(x_train_ff.shape, y_train_ff.shape)\n",
    "print(x_val_ff.shape, y_val_ff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def get_feedforward_nn():    \n",
    "    input1 = Input(shape=(75,))    \n",
    "    x = Dense(200, activation='relu')(input1)    \n",
    "    x = Dense(200, activation='relu')(x)\n",
    "    x = Dense(200, activation='relu')(x)\n",
    "    out = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                loss='mse',\n",
    "                metrics=['mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# This is called to clear the original model session in order to use TensorBoard\n",
    "K.clear_session()\n",
    "\n",
    "model_ff = get_feedforward_nn()\n",
    "model_ff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "print('start training ff')\n",
    "\n",
    "# Path to save model parameters\n",
    "weight_path_model_ff ='model_ff_nn.h5'\n",
    "# Path to write tensorboard\n",
    "tensorboard_path_model_ff = 'Graphs/ff_nn'\n",
    "\n",
    "callbacks_list_model_ff_nn = [\n",
    "#     TensorBoard(log_dir=tensorboard_path_model_ff, histogram_freq=1, write_graph=True, write_grads=True),\n",
    "    ModelCheckpoint(\n",
    "            weight_path_model_ff,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        ),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
    "]\n",
    "\n",
    "verbose = 1\n",
    "epochs, batch_size = [10,1024]\n",
    "\n",
    "model_ff.fit(x_train_ff, y_train_ff, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
    "                callbacks=callbacks_list_model_ff_nn, validation_data=(x_val_ff, y_val_ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#1:                                                                      #\n",
    "# Write a function to evaluate your model. Your function must make prediction  #\n",
    "# using the input model and return mean square error of the model.             #\n",
    "#                                                                              #\n",
    "# Hint: https://keras.io/models/model#evaluate                                 #\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "def evaluate(features, labels, model):\n",
    "    \"\"\"\n",
    "    Evaluate model on validation data\n",
    "    \"\"\"\n",
    "    pass\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use majority rule as a baseline.\n",
    "def majority_baseline(label_set):\n",
    "    unique, counts = np.unique(label_set, return_counts=True)\n",
    "    majority = unique[np.argmax(counts)]\n",
    "    baseline = 0\n",
    "    label_set = label_set.reshape(-1,1)\n",
    "    for r in label_set:\n",
    "        baseline += (majority - r) ** 2 / len(label_set)\n",
    "    pass\n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('baseline')\n",
    "print('train', majority_baseline(y_train))\n",
    "print('validate', majority_baseline(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Tensorboard #\n",
    "The code provided also have Tensorboard (a visualization tool that comes with Tensorflow). Note the part that calls it `TensorBoard(log_dir='./Graph/' + graph_name, histogram_freq=1, write_graph=True, write_grads=True)`. This tells Tensorflow to write extra outputs to the `log_dir` which can then be used for visualization.\n",
    "\n",
    "To start tensorboard do\n",
    "```\n",
    "tensorboard --logdir=/full_path_to_your_logs\n",
    "```\n",
    "from the commandline. This will launch tensorboard, you will be able to access it from a web browser by pointint the url to `<instance-ip>:6006`. You will need to enable additional firewall rules in Gcloud for this.\n",
    "\n",
    "** Make sure your logs path is in the second drive (under /data). Otherwise, your main disk will be full! **\n",
    "\n",
    "In Tensorboard, you will be able to debug your computation graph which can be hard to keep track in code. This is might seem trivial in Keras, but it is very helpful for Tensorflow. You can see a visualization of the computation graph at the `GRAPH` tab. If you see multiple dense layers (more than 4), this is caused by running the code several times without deleting the log dir. Delete the log dir and re-run the code.\n",
    "\n",
    "Next, let's look at the scalars tab, we can see the loss and accuracy on the training and validation set as they change over each epoch. This can be useful to detect overfitting.\n",
    "\n",
    "Another useful tab is the histograms tab. This plot histograms of the weights, biases, and outputs of each layer. The depth of the histograms show the change over epochs. We can see how the histograms of weights change over the training peroid. This can be used to debug vanishing gradients or getting stuck in local minimas.\n",
    "\n",
    "There are other useful tabs in Tensorboard, you can read about them in the Keras [documentation](https://keras.io/callbacks/#tensorboard) for tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard observation #\n",
    "\n",
    "**Optional TODO#1** Write your own interpretation of the logs from this example. A simple sentence or two for each tab is sufficient.\n",
    "\n",
    "**Your answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout #\n",
    "\n",
    "You might notice that the 3-layered feedforward does not use dropout at all. Now, try adding dropout to the model, run, and report the result again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#2:                                                                      #\n",
    "# Write a function that return feedforward model with dropout                  #\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "def get_fully_connected_with_dropout():    \n",
    "    pass    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "model_ff_dropout = get_fully_connected_with_dropout()\n",
    "model_ff_dropout.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO#2** Train you model with dropout below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#3:                                                                      #\n",
    "# Complete the code to train your dropout model                                #\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "print('start training ff dropout')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#4:                                                                      #\n",
    "# Complete the code to evaluate your dropout model                             #\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A fork on the road\n",
    "\n",
    "In the next Sections, we will discuss CNNs and GRUs. **PICK ONE** method to complete to finish the homework. If you do both methods, the other method counts as an optional task. Then, do the **Final Section**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Networks\n",
    "Now, you are going to implement you own 2d-convolution neural networks with the following structure.\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param\n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 5, 5, 3)           0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 3, 3, 200)         5600      \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 1800)              0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 200)               360200    \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 200)               40200     \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 1)                 201       \n",
    "=================================================================\n",
    "Total params: 406,201\n",
    "Trainable params: 406,201\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```\n",
    "These parameters are simple guidelines to save your time.    \n",
    "You can play with them in the final section which you can choose any normalization methods, activation function, as well as any hyperparameter the way you want.         \n",
    "\n",
    "Hint: You should read keras documentation to see the list of available layers and options you can use.                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#A1:                                                                     #\n",
    "# Complete the code for preparing data for training CNN                        #\n",
    "# Input for CNN should not have time step.                                     #\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "def preprocess_for_cnn(x_train, y_train, x_val, y_val):\n",
    "    pass\n",
    "    return x_train_cnn, y_train_cnn, x_val_cnn, y_val_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#A2:                                                                     #\n",
    "# Write a function that returns keras convolution nueral network model.        #\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "def get_conv2d_nn():\n",
    "    pass\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#A3:                                                                     #\n",
    "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
    "# generator, to train you models. Make sure you have validation_data as an     # \n",
    "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
    "# batch size carefully as it will affect your model's ability to converge and  #\n",
    "# time needed for one epoch.                                                   #\n",
    "#                                                                              #\n",
    "# Hint: Read about callbacks_list argument on the documentation. You might     #\n",
    "# find  ReduceLROnPlateau() and ModelCheckpoint() useful for your training     #\n",
    "# process. Feel free to use any other callback function available.             #\n",
    "################################################################################\n",
    "print('start training conv2d')\n",
    "model_cnn = get_conv2d_nn()\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(x_val_cnn, y_val_cnn, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated Recurrent Units\n",
    "\n",
    "Now, you are going to implement you own GRU network with the following structure.\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 5, 75)             0         \n",
    "_________________________________________________________________\n",
    "gru_1 (GRU)                  (None, 5, 200)            165600    \n",
    "_________________________________________________________________\n",
    "time_distributed_1 (TimeDist (None, 5, 200)            40200     \n",
    "_________________________________________________________________\n",
    "time_distributed_2 (TimeDist (None, 5, 1)              201       \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 5)                 0         \n",
    "=================================================================\n",
    "Total params: 206,001\n",
    "Trainable params: 206,001\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```\n",
    "\n",
    "\n",
    "These parameters are simple guidelines to save your time.    \n",
    "You can play with them in the final section which you can choose any normalization methods, activation function, as well as any hyperparameter the way you want.         \n",
    "The result should be better than the feedforward model and at least on par with your CNN model.    \n",
    "\n",
    "Do consult keras documentation on how to use [GRUs](https://keras.io/layers/recurrent/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#B1:                                                                     #\n",
    "# Complete the code for preparing data for training GRU                        #\n",
    "# GRU's input should has 3 dimensions.                                         #\n",
    "# The dimensions should compose of entries, time-step, and features.          #\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "def preprocess_for_gru(x_train, y_train, x_val, y_val):\n",
    "    pass\n",
    "    return x_train_gru, y_train_gru, x_val_gru, y_val_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#B2                                                                      #\n",
    "# Write a function that returns keras GRU network model.                       #\n",
    "# Your goal is to predict a precipitation of every time step.                  #\n",
    "#                                                                              #\n",
    "# Hint: You should read keras documentation to see the list of available       #\n",
    "# layers and options you can use.                                              #\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "\n",
    "def get_gru():    \n",
    "    pass\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#B3                                                                      #\n",
    "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
    "# generator, to train you models. Make sure you have validation_data as an     # \n",
    "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
    "# batch size carefully as it will affect your model's ability to converge and  #\n",
    "# time needed for one epoch.                                                   #\n",
    "#                                                                              #\n",
    "# Hint: Read about callbacks_list argument on the documentation. You might     #\n",
    "# find  ReduceLROnPlateau() and ModelCheckpoint() useful for your training     #\n",
    "# process. Feel free to use any other callback function available.             #\n",
    "################################################################################\n",
    "print('start training gru')\n",
    "model_gru = get_gru()\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(x_val_gru, y_val_gru, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Section\n",
    "# Keras playground\n",
    "\n",
    "Now, train the best model you can do for this task. You can use any model structure and function available.    \n",
    "Remember that trainig time increases with the complexity of the model. You might find TensorBoard helpful in tuning of complicated models.    \n",
    "Your model should be better than your CNN or GRU model in the previous sections.\n",
    "\n",
    "You should tune your model on training and validation set.    \n",
    "**The test set should be used only for the last evaluation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#5                                                                       #\n",
    "# Write a function that returns keras your best model. You can use anything    #\n",
    "# you want. The goal here is to create the best model you can think of.        #\n",
    "#                                                                              #\n",
    "# Hint: You should read keras documentation to see the list of available       #\n",
    "# layers and options you can use.                                              #\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "\n",
    "def get_my_best_model():\n",
    "    pass\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO#6                                                                       #\n",
    "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
    "# generator, to train you models. Make sure you have validation_data as an     # \n",
    "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
    "# batch size carefully as it will affect your model's ability to converge and  #\n",
    "# time needed for one epoch.                                                   #\n",
    "#                                                                              #\n",
    "# Hint: Read about callbacks_list argument on the documentation. You might     #\n",
    "# find  ReduceLROnPlateau() and ModelCheckpoint() useful for your training     #\n",
    "# process. Feel free to use any other callback function available.             #\n",
    "################################################################################\n",
    "print('start training the best model')\n",
    "my_best_model = get_my_best_model()\n",
    "################################################################################\n",
    "#                            WRITE YOUR CODE BELOW                             #\n",
    "################################################################################\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(x_val_best, y_val_best, model)\n",
    "evaluate(x_test_best, y_test_best, model)\n",
    "#Also evaluate your fully-connected model and CNN/GRU model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get full credit for this part, your best model should be better than the previous models on the **test set**. The top 5 students will recieve 2 additional points. The top student will recieve another 2 additional points on top."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
